{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import shuffle\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from numpy import ndarray\n",
    "from scipy import linalg, stats\n",
    "from scipy.spatial.distance import cityblock\n",
    "from typing import List, Tuple\n",
    "\n",
    "combined_directory = \"./combined/\"\n",
    "directory_n_1 = \"./chars/\"\n",
    "directory_n_2 = \"./chars 2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes a directory path and returns all the names of the subdirectories and their paths\n",
    "def open_directory(directory_path):\n",
    "    subdirectory_names = os.listdir(directory_path)\n",
    "    subdirectory_paths = [directory_path + subdirectory_name + \"/\" for subdirectory_name in subdirectory_names]\n",
    "    return subdirectory_paths, subdirectory_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes a list of image paths and returns a list of image\n",
    "def open_images(image_paths):\n",
    "    image_arrays = [np.array(Image.open(image_path)) for image_path in image_paths]\n",
    "    for image_path in image_paths:\n",
    "        image_arrays.append(np.array(Image.open(image_path)))\n",
    "    return image_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Takes a list of image np.arrays and turns them into a large feature vector array where rows correnspond to images and columns correspond to features (pixels) of the image\n",
    "def images_to_feature_vectors(image_arrays):\n",
    "    images = open_images(image_arrays)\n",
    "    h, w = images[0].shape\n",
    "    n_features = h * w\n",
    "    fvectors = np.empty((len(images), n_features))\n",
    "    for i, image in enumerate(images):\n",
    "        fvectors[i, :] = image.reshape(1, n_features)\n",
    "    return fvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits an image list into training and testing data\n",
    "def split_two(image_list, ratio=[0.7, 0.3]):\n",
    "    train_ratio = ratio[0]\n",
    "    indices_for_splittin = [int(len(image_list) * train_ratio)]\n",
    "    train, test = np.split(image_list, indices_for_splittin)\n",
    "    return train, test\n",
    "\n",
    "#Splits an image list into training, validation and testing data\n",
    "def split_three(image_list, ratio=[0.8, 0.1, 0.1]):\n",
    "    train_r, val_r, test_r = ratio\n",
    "    assert(np.sum(ratio) == 1.0)\n",
    "    indicies_for_splitting = [int(len(image_list) * train_r), int(len(image_list) * (train_r+val_r))]\n",
    "    train, val, test = np.split(image_list, indicies_for_splitting)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes the path of a directory where every image is placed into a directory with the name of the label\n",
    "#and returns a dictionary with the feature vectors and their corresponding labels\n",
    "def label_data(directory):\n",
    "    data_labelled = {}\n",
    "    data_fvectors = []\n",
    "    data_labels = []\n",
    "    subdirectory_paths, subdirectory_names = open_directory(directory)\n",
    "    for i in range(len(subdirectory_names)):\n",
    "        images = os.listdir(subdirectory_paths[i])\n",
    "        images = [subdirectory_paths[i] + \"/\" + image for image in images]\n",
    "        data_fv = images_to_feature_vectors(images)\n",
    "        for fv in data_fv:\n",
    "            data_fvectors.append(fv)\n",
    "            data_labels.append(subdirectory_names[i])\n",
    "    data_labelled[\"fvectors\"] = data_fvectors\n",
    "    data_labelled[\"labels\"] = data_labels\n",
    "\n",
    "    return data_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does the same as label_data but it also splits the images into training and testing and returns seperate dictionaries\n",
    "def split_train_test(directory):\n",
    "    train_model = {}\n",
    "    train_fvectors = []\n",
    "    train_labels = []\n",
    "    test_model = {}\n",
    "    test_fvectors = []\n",
    "    test_labels = []\n",
    "    subdirectory_paths, subdirectory_names = open_directory(directory)\n",
    "    for i in range(len(subdirectory_names)):\n",
    "        images = os.listdir(subdirectory_paths[i])\n",
    "        shuffle(images)\n",
    "        images = [subdirectory_paths[i] + \"/\" + image for image in images]\n",
    "        train, test = split_two(images)\n",
    "        train_fv = images_to_feature_vectors(train)\n",
    "        for fv in train_fv:\n",
    "            train_fvectors.append(fv)\n",
    "            train_labels.append(subdirectory_names[i])\n",
    "        test_fv = images_to_feature_vectors(test)\n",
    "        for fv in test_fv:\n",
    "            test_fvectors.append(fv)\n",
    "            test_labels.append(subdirectory_names[i])\n",
    "    train_model[\"fvectors\"] = train_fvectors\n",
    "    train_model[\"labels\"] = train_labels\n",
    "    test_model[\"fvectors\"] = test_fvectors\n",
    "    test_model[\"labels\"] = test_labels\n",
    "\n",
    "    return train_model, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the training model to a pickle file\n",
    "def save_pickle(data: dict) -> None:\n",
    "    a_file = open(\"data.pkl\", \"wb\")\n",
    "    pickle.dump(data, a_file)\n",
    "    a_file.close()\n",
    "\n",
    "#Loads the training model from the pickle file\n",
    "def load_pickle() -> dict:\n",
    "    a_file = open(\"data.pkl\", \"rb\")\n",
    "    model = pickle.load(a_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computes the dot distance between arrays of training and testing data and returns the distance where rows correspond to test images and columns correspond to train images, very quick\n",
    "def dot_distance(training, testing):\n",
    "    tdott = np.dot(testing, training.transpose())\n",
    "    modtrain = np.sqrt(np.sum(training*training, axis=1))\n",
    "    modtest = np.sqrt(np.sum(testing*testing, axis=1))\n",
    "    dist = -tdott / np.outer(modtest, modtrain.transpose())\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes the euclidean distance between arrays of training and testing data, pretty slow\n",
    "def euclidean_distance(training, testing):\n",
    "    dist = np.full([len(testing), len(training)], 0)\n",
    "    for testrow in range(0, testing.shape[0]):\n",
    "        for trainrow in range(0, training.shape[0]):\n",
    "            dist[testrow][trainrow] = np.linalg.norm(testing[testrow]-training[trainrow])\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computes the manhattan distance between arrays of training and testing data, extremely slow\n",
    "def manhattan_distance(training, testing):\n",
    "    dist = np.full([len(testing), len(training)], 0)\n",
    "    for testrow in range(0, testing.shape[0]):\n",
    "        for trainrow in range(0, training.shape[0]):\n",
    "            dist[testrow][trainrow] = cityblock(testing[testrow], training[trainrow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNC = 5 #K in K nearest neighbours\n",
    "\n",
    "#Takes a training dict and a testing dict, computes the distance between the feature vectors, finds the k nearest images, extracts their labels, \n",
    "#finds the most common label, and classifies it as such. Returns labels in the same order as the test feature vectors\n",
    "def classify(train_model:dict, test_data:dict, k, distance) -> List[str]:\n",
    "    train = np.array(train_model[\"fvectors\"])\n",
    "    train_labels = train_model[\"labels\"]\n",
    "    test = np.array(test_data[\"fvectors\"])\n",
    "\n",
    "    if distance == 0:\n",
    "        dist = dot_distance(train, test)\n",
    "    else:\n",
    "        dist = euclidean_distance(train, test)\n",
    "    \n",
    "    knearest = np.argsort(dist, axis=1)[:, 0:k]\n",
    "    klabels = []\n",
    "    for i in range(len(knearest)):\n",
    "        individual_labels = []\n",
    "        for j in range(len(knearest[0])):\n",
    "            individual_labels.append(train_labels[knearest[i][j]])\n",
    "        klabels.append(individual_labels)\n",
    "    klabels = pd.DataFrame(klabels)\n",
    "    labels = klabels.mode(axis='columns')\n",
    "    label = np.array(labels[0].tolist())\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computes the accuracy of the model by running classify and checking the percentage of true labels\n",
    "def evaluate(train_model: dict, test:dict, k, distance) -> Tuple[float, float]:\n",
    "\n",
    "    true_labels = test[\"labels\"]\n",
    "    output_labels = classify(train_model, test, k, distance)\n",
    "    n_of_correct_labels = 0\n",
    "    #wrong_predictions = []\n",
    "    #print(len(true_labels))\n",
    "    for i in range(len(true_labels)):\n",
    "        if output_labels[i] == true_labels[i]:\n",
    "            n_of_correct_labels += 1\n",
    "    #     else:\n",
    "    #         wrong_labels = []\n",
    "    #         wrong_labels.append(output_labels[i])\n",
    "    #         wrong_labels.append(true_labels[i])\n",
    "    #         wrong_predictions.append(wrong_labels)\n",
    "    # print(len(wrong_predictions))\n",
    "    # print(wrong_predictions)\n",
    "    score= 100.0 * n_of_correct_labels / len(true_labels)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a random test/train split and runs the classifier once\n",
    "def test_one(directory_of_images, k, distance):\n",
    "    #train = label_data(directory_of_test_images)\n",
    "    #test = label_data(directory_of_images)\n",
    "    train, test = split_train_test(directory_of_images)\n",
    "    #save_pickle(train)\n",
    "    return evaluate(test, train, k, distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the classifier n times, each time creating a new training/testing split, then prints the average accuracy of the n runs\n",
    "def test_n_times(directory_of_images, k, n, distance):\n",
    "    accuracy = []\n",
    "    for i in range(n):\n",
    "        accuracy.append(test_one(combined_directory, k, distance))\n",
    "    average=sum(accuracy)/n\n",
    "    final_score = \"Average score for k=\" + str(k) + \" = \" + str(round(average, 2))\n",
    "    print(final_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for k=3 = 95.2\n",
      "Average score for k=8 = 93.82\n",
      "Average score for k=5 = 94.44\n",
      "Average score for k=4 = 93.88\n",
      "Average score for k=6 = 94.2Average score for k=7 = 94.21\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "t1 = threading.Thread(target=test_n_times, args=(combined_directory, 3, 100, 0))\n",
    "t2 = threading.Thread(target=test_n_times, args=(combined_directory, 4, 100, 0))\n",
    "t3 = threading.Thread(target=test_n_times, args=(combined_directory, 5, 100, 0))\n",
    "t4 = threading.Thread(target=test_n_times, args=(combined_directory, 6, 100, 0))\n",
    "t5 = threading.Thread(target=test_n_times, args=(combined_directory, 7, 100, 0))\n",
    "t6 = threading.Thread(target=test_n_times, args=(combined_directory, 8, 100, 0))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()\n",
    "t5.start()\n",
    "t6.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "t4.join()\n",
    "t5.join()\n",
    "t6.join()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "t7 = threading.Thread(target=test_n_times, args=(combined_directory, 3, 100, 1))\n",
    "t8 = threading.Thread(target=test_n_times, args=(combined_directory, 4, 100, 1))\n",
    "t9 = threading.Thread(target=test_n_times, args=(combined_directory, 5, 100, 1))\n",
    "t10 = threading.Thread(target=test_n_times, args=(combined_directory, 6, 100, 1))\n",
    "t11 = threading.Thread(target=test_n_times, args=(combined_directory, 7, 100, 1))\n",
    "t12 = threading.Thread(target=test_n_times, args=(combined_directory, 8, 100, 1))\n",
    "\n",
    "t7.start()\n",
    "t8.start()\n",
    "t9.start()\n",
    "t10.start()\n",
    "t11.start()\n",
    "t12.start()\n",
    "\n",
    "t7.join()\n",
    "t8.join()\n",
    "t9.join()\n",
    "t10.join()\n",
    "t11.join()\n",
    "t12.join()\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('alpd-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0b24a549299692660444c5a130c8d27707466c03701f1457806aa7aa3ac4118"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
