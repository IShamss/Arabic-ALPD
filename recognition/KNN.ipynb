{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "from numpy import ndarray\n",
    "from scipy import linalg, stats\n",
    "from typing import List, Tuple\n",
    "\n",
    "combined_directory = \"./New folder/combined/\"\n",
    "directory_n_1 = \"./batch 2/\"\n",
    "directory_n_2 = \"./batch 3/\"\n",
    "test_images = \"./test/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Takes a directory path and returns all the names of the subdirectories and their paths\n",
    "def open_directory(directory_path):\n",
    "    names = os.listdir(directory_path)\n",
    "    paths = [directory_path + name + \"/\" for name in names]\n",
    "    return paths, names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def open_dic(directory_path):\n",
    "    names = os.listdir(directory_path)\n",
    "    paths = [directory_path + name for name in names]\n",
    "    return paths, names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Takes a list of image paths and returns a list of image\n",
    "def open_images(image_paths):\n",
    "    image_arrays = [np.array(Image.open(image_path)) for image_path in image_paths]\n",
    "    return image_arrays"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#Takes a list of image np.arrays and turns them into a large feature vector array where rows correnspond to images and columns correspond to features (pixels) of the image\n",
    "def images_to_feature_vectors(image_paths):\n",
    "    images = open_images(image_paths)\n",
    "    h, w = images[0].shape\n",
    "    n_features = h * w\n",
    "    fvectors = np.empty((len(images), n_features))\n",
    "    for i, image in enumerate(images):\n",
    "        fvectors[i, :] = image.reshape(1, n_features)\n",
    "    return fvectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Splits an image list into training and testing data\n",
    "def split_two(image_list, ratio=[0.7, 0.3]):\n",
    "    train_ratio = ratio[0]\n",
    "    indices_for_splittin = [int(len(image_list) * train_ratio)]\n",
    "    train, test = np.split(image_list, indices_for_splittin)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "#Splits an image list into training, validation and testing data\n",
    "def split_three(image_list, ratio=[0.8, 0.1, 0.1]):\n",
    "    train_r, val_r, test_r = ratio\n",
    "    assert (np.sum(ratio) == 1.0)\n",
    "    indicies_for_splitting = [int(len(image_list) * train_r), int(len(image_list) * (train_r + val_r))]\n",
    "    train, val, test = np.split(image_list, indicies_for_splitting)\n",
    "    return train, val, test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Takes the path of a directory where every image is placed into a directory with the name of the label\n",
    "#and returns a dictionary with the feature vectors and their corresponding labels\n",
    "def label_data(directory):\n",
    "    data_labelled = {}\n",
    "    data_fvectors = []\n",
    "    data_labels = []\n",
    "    subdirectory_paths, subdirectory_names = open_directory(directory)\n",
    "    for i in range(len(subdirectory_names)):\n",
    "        images = os.listdir(subdirectory_paths[i])\n",
    "        images = [subdirectory_paths[i] + \"/\" + image for image in images]\n",
    "        data_fv = images_to_feature_vectors(images)\n",
    "        for fv in data_fv:\n",
    "            data_fvectors.append(fv)\n",
    "            data_labels.append(subdirectory_names[i])\n",
    "    data_labelled[\"fvectors\"] = data_fvectors\n",
    "    data_labelled[\"labels\"] = data_labels\n",
    "\n",
    "    return data_labelled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Does the same as label_data but it also splits the images into training and testing and returns seperate dictionaries\n",
    "def split_train_test(directory):\n",
    "    train_model = {}\n",
    "    train_fvectors = []\n",
    "    train_labels = []\n",
    "    test_model = {}\n",
    "    test_fvectors = []\n",
    "    test_labels = []\n",
    "    subdirectory_paths, subdirectory_names = open_directory(directory)\n",
    "    for i in range(len(subdirectory_names)):\n",
    "        images = os.listdir(subdirectory_paths[i])\n",
    "        shuffle(images)\n",
    "        images = [subdirectory_paths[i] + \"/\" + image for image in images]\n",
    "        train, test = split_two(images)\n",
    "        train_fv = images_to_feature_vectors(train)\n",
    "        for fv in train_fv:\n",
    "            train_fvectors.append(fv)\n",
    "            train_labels.append(subdirectory_names[i])\n",
    "        test_fv = images_to_feature_vectors(test)\n",
    "        for fv in test_fv:\n",
    "            test_fvectors.append(fv)\n",
    "            test_labels.append(subdirectory_names[i])\n",
    "    train_model[\"fvectors\"] = train_fvectors\n",
    "    train_model[\"labels\"] = train_labels\n",
    "    test_model[\"fvectors\"] = test_fvectors\n",
    "    test_model[\"labels\"] = test_labels\n",
    "\n",
    "    return train_model, test_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Save the training model to a pickle file\n",
    "def save_pickle(data: dict) -> None:\n",
    "    a_file = open(\"data.pkl\", \"wb\")\n",
    "    pickle.dump(data, a_file)\n",
    "    a_file.close()\n",
    "\n",
    "\n",
    "#Loads the training model from the pickle file\n",
    "def load_pickle() -> dict:\n",
    "    a_file = open(\"data.pkl\", \"rb\")\n",
    "    model = pickle.load(a_file)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Computes the cosine distance between arrays of training and testing data and returns the distance where rows correspond to test images and columns correspond to train images, very quick\n",
    "def cosine_similarity(training, testing):\n",
    "    tdott = np.dot(testing, training.transpose())\n",
    "    modtrain = np.sqrt(np.sum(training * training, axis=1))\n",
    "    modtest = np.sqrt(np.sum(testing * testing, axis=1))\n",
    "    dist = -tdott / np.outer(modtest, modtrain.transpose())\n",
    "    return dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#computes the euclidean distance between arrays of training and testing data, pretty slow\n",
    "def euclidean_distance(training, testing):\n",
    "    dist = np.full([len(testing), len(training)], 0)\n",
    "    for testrow in range(0, testing.shape[0]):\n",
    "        for trainrow in range(0, training.shape[0]):\n",
    "            dist[testrow][trainrow] = np.linalg.norm(testing[testrow] - training[trainrow])\n",
    "    return dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KNNC = 5  #K in K nearest neighbours\n",
    "\n",
    "\n",
    "#Takes a training dict and a testing dict, computes the distance between the feature vectors, finds the k nearest images, extracts their labels,\n",
    "#finds the most common label, and classifies it as such. Returns labels in the same order as the test feature vectors\n",
    "def classify(train_model: dict, test_fvectors, k, distance) -> List[str]:\n",
    "    train = np.array(train_model[\"fvectors\"])\n",
    "    train_labels = train_model[\"labels\"]\n",
    "\n",
    "    #Compute distance\n",
    "    if distance == 0:\n",
    "        dist = cosine_similarity(train, test_fvectors)\n",
    "    else:\n",
    "        dist = euclidean_distance(train, test_fvectors)\n",
    "\n",
    "    #Extract k nearest images\n",
    "    knearest = np.argsort(dist, axis=1)[:, 0:k]\n",
    "\n",
    "    #Extract the labels of the k nearest neighbours for each test image\n",
    "    klabels = []\n",
    "    for i in range(len(knearest)):\n",
    "        individual_labels = []\n",
    "        for j in range(len(knearest[0])):\n",
    "            individual_labels.append(train_labels[knearest[i][j]])\n",
    "        klabels.append(individual_labels)\n",
    "\n",
    "    #Find the most comon label and classify\n",
    "    klabels = pd.DataFrame(klabels)\n",
    "    labels = klabels.mode(axis='columns')\n",
    "    label = np.array(labels[0].tolist())\n",
    "    return label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Computes the accuracy of the model by running classify and checking the percentage of true labels\n",
    "def evaluate(train_model: dict, test: dict, k, distance) -> Tuple[float, float]:\n",
    "    true_labels = test[\"labels\"]\n",
    "    test_fvectors = test[\"fvectors\"]\n",
    "    output_labels = classify(train_model, test_fvectors, k, distance)\n",
    "    n_of_correct_labels = 0\n",
    "    #wrong_predictions = []\n",
    "    #print(len(true_labels))\n",
    "    for i in range(len(true_labels)):\n",
    "        if output_labels[i] == true_labels[i]:\n",
    "            n_of_correct_labels += 1\n",
    "    #     else:\n",
    "    #         wrong_labels = []\n",
    "    #         wrong_labels.append(output_labels[i])\n",
    "    #         wrong_labels.append(true_labels[i])\n",
    "    #         wrong_predictions.append(wrong_labels)\n",
    "    # print(len(wrong_predictions))\n",
    "    # print(wrong_predictions)\n",
    "    score = 100.0 * n_of_correct_labels / len(true_labels)\n",
    "    return score\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Creates a random test/train split and runs the classifier once\n",
    "def test_one(directory_of_images, k, distance):\n",
    "    #train = label_data(directory_of_test_images)\n",
    "    #test = label_data(directory_of_images)\n",
    "    train, test = split_train_test(directory_of_images)\n",
    "    #save_pickle(train)\n",
    "    return evaluate(test, train, k, distance)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Runs the classifier n times, each time creating a new training/testing split, then prints the average accuracy of the n runs\n",
    "def test_n_times(directory_of_images, k, n, distance):\n",
    "    accuracy = []\n",
    "    for i in range(n):\n",
    "        accuracy.append(test_one(combined_directory, k, distance))\n",
    "    average = sum(accuracy) / n\n",
    "    final_score = \"Average score for k=\" + str(k) + \" = \" + str(round(average, 2))\n",
    "    print(final_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Saves the model using train data directory\n",
    "def save_model(train_data_directory):\n",
    "    model = label_data(train_data_directory)\n",
    "    save_pickle(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_model(combined_directory)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Takes the directory path of the images we want to classify and returns the corresponding labels\n",
    "def classify_unlabelled_directory(segmented_image_directory):\n",
    "    image_paths, _ = open_dic(segmented_image_directory)\n",
    "    image_fvectors = images_to_feature_vectors(image_paths)\n",
    "    train_model = load_pickle()\n",
    "    labels = classify(train_model, image_fvectors, 3, 0)\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predictChars(listOfChars):\n",
    "    mappings = {\n",
    "        \"1\": \"1\",\n",
    "        \"2\": \"2\",\n",
    "        \"3\": \"3\",\n",
    "        \"4\": \"4\",\n",
    "        \"5\": \"5\",\n",
    "        \"6\": \"6\",\n",
    "        \"7\": \"7\",\n",
    "        \"8\": \"8\",\n",
    "        \"9\": \"9\",\n",
    "        \"10\": \"أ\",\n",
    "        \"11\": \"ب\",\n",
    "        \"12\": \"ج\",\n",
    "        \"13\": \"د\",\n",
    "        \"14\": \"ر\",\n",
    "        \"15\": \"س\",\n",
    "        \"16\": \"ص\",\n",
    "        \"17\": \"ط\",\n",
    "        \"18\": \"ع\",\n",
    "        \"19\": \"ف\",\n",
    "        \"20\": \"ق\",\n",
    "        \"21\": \"ل\",\n",
    "        \"22\": \"م\",\n",
    "        \"23\": \"ن\",\n",
    "        \"24\": \"ه\",\n",
    "        \"25\": \"و\",\n",
    "        \"26\": \"ي\",\n",
    "    }\n",
    "\n",
    "    # list=[\"1\",\"2\",\"a\",\"f\"]\n",
    "    finalChar = []\n",
    "    for char in listOfChars:\n",
    "        finalChar.append(mappings[char])\n",
    "    return finalChar"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_chars = classify_unlabelled_directory(test_images)\n",
    "print(predictChars(predicted_chars))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('alpd-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0b24a549299692660444c5a130c8d27707466c03701f1457806aa7aa3ac4118"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}